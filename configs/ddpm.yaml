# DDPM Configuration

model:
  diffusion_steps: 2500
  beta2_start: 0.0001
  beta2_end: 0.02
  time_embed_dim: 32
  hidden_units: 64

training:
  epochs: 1000
  batch_size: 4096
  learning_rate: 0.001
  lr_decay: 0.999
